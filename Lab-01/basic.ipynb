{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4648ba1",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'mediapipe.tasks.python.vision' has no attribute 'Image'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 23\u001b[39m\n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m# Global variable to store the latest detection result\u001b[39;00m\n\u001b[32m     21\u001b[39m latest_result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mvisualize_result\u001b[39m(result: PoseLandmarkerResult, output_image: \u001b[43mvision\u001b[49m\u001b[43m.\u001b[49m\u001b[43mImage\u001b[49m, timestamp_ms: \u001b[38;5;28mint\u001b[39m):\n\u001b[32m     24\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Callback invoked by the landmarker (LIVE_STREAM mode).\"\"\"\u001b[39;00m\n\u001b[32m     25\u001b[39m     \u001b[38;5;28;01mglobal\u001b[39;00m latest_result\n",
      "\u001b[31mAttributeError\u001b[39m: module 'mediapipe.tasks.python.vision' has no attribute 'Image'"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "from mediapipe.tasks import python\n",
    "from mediapipe.tasks.python import vision\n",
    "from mediapipe import solutions\n",
    "from mediapipe.framework.formats import landmark_pb2\n",
    "import numpy as np\n",
    "\n",
    "# Load the pose landmarker model file (download from MediaPipe docs)\n",
    "model_path = 'pose_landmarker_lite.task'\n",
    "\n",
    "# API symbols\n",
    "BaseOptions = python.BaseOptions\n",
    "PoseLandmarker = vision.PoseLandmarker\n",
    "PoseLandmarkerOptions = vision.PoseLandmarkerOptions\n",
    "PoseLandmarkerResult = vision.PoseLandmarkerResult\n",
    "VisionRunningMode = vision.RunningMode\n",
    "\n",
    "# Global variable to store the latest detection result\n",
    "latest_result = None\n",
    "\n",
    "# Note: avoid annotating with `vision.Image` since some versions don't expose it\n",
    "def visualize_result(result: PoseLandmarkerResult, output_image, timestamp_ms: int):\n",
    "    \"\"\"Callback invoked by the landmarker (LIVE_STREAM mode).\"\"\"\n",
    "    global latest_result\n",
    "    latest_result = result\n",
    "\n",
    "def run_real_time_pose_detection():\n",
    "    \"\"\"Runs real-time pose detection from the webcam.\"\"\"\n",
    "    options = PoseLandmarkerOptions(\n",
    "        base_options=BaseOptions(model_asset_path=model_path),\n",
    "        running_mode=VisionRunningMode.LIVE_STREAM,\n",
    "        result_callback=visualize_result,\n",
    "    )\n",
    "\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Cannot open camera\")\n",
    "        return\n",
    "\n",
    "    with PoseLandmarker.create_from_options(options) as landmarker:\n",
    "        while cap.isOpened():\n",
    "            success, frame = cap.read()\n",
    "            if not success:\n",
    "                print(\"Ignoring empty camera frame.\")\n",
    "                continue\n",
    "\n",
    "            # Convert BGR (OpenCV) to RGB and create a TensorImage\n",
    "            rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            try:\n",
    "                mp_image = vision.TensorImage.create_from_array(rgb_frame)\n",
    "            except Exception:\n",
    "                # Fallback: try the Tasks Image factory if available\n",
    "                try:\n",
    "                    mp_image = vision.Image.create_from_array(rgb_frame)\n",
    "                except Exception:\n",
    "                    # Last-resort: use raw numpy array (may fail depending on version)\n",
    "                    mp_image = rgb_frame\n",
    "\n",
    "            # Timestamp in milliseconds\n",
    "            timestamp_ms = int(time.time() * 1000)\n",
    "\n",
    "            # Send the frame to the landmarker for asynchronous processing\n",
    "            landmarker.detect_async(mp_image, timestamp_ms)\n",
    "\n",
    "            # If we have a recent result, draw landmarks\n",
    "            if latest_result and getattr(latest_result, 'pose_landmarks', None):\n",
    "                annotated_image = np.copy(frame)\n",
    "                for detection in latest_result.pose_landmarks:\n",
    "                    pose_landmarks_proto = landmark_pb2.NormalizedLandmarkList()\n",
    "                    pose_landmarks_proto.landmark.extend([\n",
    "                        landmark_pb2.NormalizedLandmark(x=lm.x, y=lm.y, z=lm.z) for lm in detection\n",
    "                    ])\n",
    "                    solutions.drawing_utils.draw_landmarks(\n",
    "                        annotated_image,\n",
    "                        pose_landmarks_proto,\n",
    "                        solutions.pose.POSE_CONNECTIONS,\n",
    "                        solutions.drawing_styles.get_default_pose_landmarks_style(),\n",
    "                    )\n",
    "                cv2.imshow('MediaPipe Pose Landmarker', annotated_image)\n",
    "            else:\n",
    "                cv2.imshow('MediaPipe Pose Landmarker', frame)\n",
    "\n",
    "            # Break loop on 'q' key press\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_real_time_pose_detection()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
